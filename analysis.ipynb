{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9a2a67",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import functions as F\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1e70d",
   "metadata": {},
   "source": [
    "### Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402eeb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/18 20:00:15 WARN Utils: Your hostname, cachyos, resolves to a loopback address: 127.0.1.1; using 192.168.1.236 instead (on interface wlan0)\n",
      "25/12/18 20:00:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/18 20:00:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Default settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedditDepressionAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.default.parallelism\", \"200\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0efe2f",
   "metadata": {},
   "source": [
    "### Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9229a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/18 20:00:33 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------------+---------------+-----------+--------+-----------+--------------+------------------+-----------------------------+----------------------+---------------------+------------------------+-----------------+-----------------------+-----------------+---------------+-----------------+--------------------+--------------+--------+-------------+---------+----------+--------------+--------+------------+--------+-------+------------------+------------+-------+-----------+----------------+---------------------+---------------+-------------+---------------+-----+------+----+-------+---------+------+--------+------+----------+-----+----------------------+----------------+-------+-------------------+----------------------+------------------+-------+--------+-----+---------------------------+--------------------+-------------------+----------------------+---------------+---------------------+---------------+------+-----+--------------------+----------+--------+-------------+----------------+-----------+----+---------+------------+--------------+-----------+-------+-----------------------+--------------------+------+---------------+---------+-------+-----------------+---------------+----+----------+--------------+----------+-------------------+--------------+------------+-------------+--------+-----+-----+------------+--------------------+---------+-------------+------------+-------+--------+----------+------------+-----------------------+---------------------+--------------+--------------+---------+----------------+---------------+--------------------+----------------+---------------------+--------------+----------+----+------------+--------------------+----------------------+------------+----------+-------+----------------+----+\n",
      "|_meta|all_awardings|allow_live_comments|approved_at_utc|approved_by|archived|     author|author_cakeday|author_created_utc|author_flair_background_color|author_flair_css_class|author_flair_richtext|author_flair_template_id|author_flair_text|author_flair_text_color|author_flair_type|author_fullname|author_is_blocked|author_patreon_flair|author_premium|awarders|banned_at_utc|banned_by|brand_safe|call_to_action|can_gild|can_mod_post|category|clicked|content_categories|contest_mode|created|created_utc|crosspost_parent|crosspost_parent_list|discussion_type|distinguished|         domain|downs|edited|from|from_id|from_kind|gilded|gildings|hidden|hide_score|   id|is_created_from_ads_ui|is_crosspostable|is_meta|is_original_content|is_reddit_media_domain|is_robot_indexable|is_self|is_video|likes|link_flair_background_color|link_flair_css_class|link_flair_richtext|link_flair_template_id|link_flair_text|link_flair_text_color|link_flair_type|locked|media|         media_embed|media_only|mod_note|mod_reason_by|mod_reason_title|mod_reports|name|no_follow|num_comments|num_crossposts|num_reports|over_18|parent_whitelist_status|           permalink|pinned|post_categories|post_hint|preview|previous_selftext|previous_visits|pwls|quarantine|removal_reason|removed_by|removed_by_category|report_reasons|retrieved_on|retrieved_utc|rte_mode|saved|score|secure_media|  secure_media_embed| selftext|selftext_html|send_replies|spoiler|stickied| subreddit|subreddit_id|subreddit_name_prefixed|subreddit_subscribers|subreddit_type|suggested_sort|thumbnail|thumbnail_height|thumbnail_width|               title|top_awarded_type|total_awards_received|treatment_tags|updated_on| ups|upvote_ratio|                 url|url_overridden_by_dest|user_reports|view_count|visited|whitelist_status| wls|\n",
      "+-----+-------------+-------------------+---------------+-----------+--------+-----------+--------------+------------------+-----------------------------+----------------------+---------------------+------------------------+-----------------+-----------------------+-----------------+---------------+-----------------+--------------------+--------------+--------+-------------+---------+----------+--------------+--------+------------+--------+-------+------------------+------------+-------+-----------+----------------+---------------------+---------------+-------------+---------------+-----+------+----+-------+---------+------+--------+------+----------+-----+----------------------+----------------+-------+-------------------+----------------------+------------------+-------+--------+-----+---------------------------+--------------------+-------------------+----------------------+---------------+---------------------+---------------+------+-----+--------------------+----------+--------+-------------+----------------+-----------+----+---------+------------+--------------+-----------+-------+-----------------------+--------------------+------+---------------+---------+-------+-----------------+---------------+----+----------+--------------+----------+-------------------+--------------+------------+-------------+--------+-----+-----+------------+--------------------+---------+-------------+------------+-------+--------+----------+------------+-----------------------+---------------------+--------------+--------------+---------+----------------+---------------+--------------------+----------------+---------------------+--------------+----------+----+------------+--------------------+----------------------+------------+----------+-------+----------------+----+\n",
      "| NULL|         NULL|               NULL|           NULL|       NULL|    true|  [deleted]|          NULL|              NULL|                             |                  NULL|                 NULL|                    NULL|             NULL|                   dark|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|      true|          NULL|   false|        NULL|    NULL|   NULL|              NULL|       false|   NULL| 1230773002|            NULL|                 NULL|           NULL|         NULL|self.depression| NULL| false|NULL|   NULL|     NULL|     0|    NULL| false|     false|7mqco|                  NULL|           false|   NULL|               NULL|                 false|              NULL|   true|   false| NULL|                       NULL|                NULL|                 []|                  NULL|           NULL|                 dark|           text| false| NULL|{NULL, NULL, NULL...|      NULL|    NULL|         NULL|            NULL|       NULL|NULL|     true|           0|             0|       NULL|  false|                all_ads|/r/depression/com...|  NULL|           NULL|     NULL|   NULL|             NULL|           NULL|NULL|      NULL|          NULL|      NULL|               NULL|          NULL|  1522770236|         NULL|markdown| NULL|    1|        NULL|{NULL, NULL, NULL...|[deleted]|         NULL|        true|  false|   false|depression|    t5_2qqqf|           r/depression|                 NULL|        public|    confidence|  default|            NULL|           NULL|Girls, the future...|            NULL|                 NULL|          NULL|      NULL|NULL|        NULL|https://www.reddi...|                  NULL|        NULL|      NULL|   NULL|         all_ads|NULL|\n",
      "| NULL|         NULL|               NULL|           NULL|       NULL|    true|HappyRabbit|          NULL|              NULL|                         NULL|                  NULL|                   []|                    NULL|             NULL|                   NULL|             text|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|      true|          NULL|    true|        NULL|    NULL|   NULL|              NULL|       false|   NULL| 1230773772|            NULL|                 NULL|           NULL|         NULL|self.depression| NULL| false|NULL|   NULL|     NULL|     0|    NULL| false|     false|7mqdw|                  NULL|           false|   NULL|               NULL|                 false|              NULL|   true|   false| NULL|                       NULL|                NULL|                 []|                  NULL|           NULL|                 dark|           text| false| NULL|{NULL, NULL, NULL...|      NULL|    NULL|         NULL|            NULL|       NULL|NULL|     true|           1|             0|       NULL|  false|                all_ads|/r/depression/com...|  NULL|           NULL|     NULL|   NULL|             NULL|           NULL|NULL|      NULL|          NULL|      NULL|               NULL|          NULL|  1522770237|         NULL|markdown| NULL|    1|        NULL|{NULL, NULL, NULL...|[removed]|         NULL|        true|  false|   false|depression|    t5_2qqqf|           r/depression|                 NULL|        public|    confidence|  default|            NULL|           NULL|    Girls and stuff.|            NULL|                 NULL|          NULL|      NULL|NULL|        NULL|https://www.reddi...|                  NULL|        NULL|      NULL|   NULL|         all_ads|NULL|\n",
      "| NULL|         NULL|               NULL|           NULL|       NULL|    true|  [deleted]|          NULL|              NULL|                             |                  NULL|                 NULL|                    NULL|             NULL|                   dark|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|      true|          NULL|   false|        NULL|    NULL|   NULL|              NULL|       false|   NULL| 1230780179|            NULL|                 NULL|           NULL|         NULL|i40.tinypic.com| NULL| false|NULL|   NULL|     NULL|     0|    NULL| false|     false|7mqo7|                  NULL|            true|   NULL|               NULL|                 false|              NULL|  false|   false| NULL|                       NULL|                NULL|                 []|                  NULL|           NULL|                 dark|           text| false| NULL|{NULL, NULL, NULL...|      NULL|    NULL|         NULL|            NULL|       NULL|NULL|    false|           2|             0|       NULL|  false|                all_ads|/r/depression/com...|  NULL|           NULL|     NULL|   NULL|             NULL|           NULL|NULL|      NULL|          NULL|      NULL|               NULL|          NULL|  1522770244|         NULL|markdown| NULL|    7|        NULL|{NULL, NULL, NULL...|         |         NULL|        true|  false|   false|depression|    t5_2qqqf|           r/depression|                 NULL|        public|    confidence|         |            NULL|           NULL|I had plans to go...|            NULL|                 NULL|          NULL|      NULL|NULL|        NULL|http://i40.tinypi...|                  NULL|        NULL|      NULL|   NULL|         all_ads|NULL|\n",
      "| NULL|         NULL|               NULL|           NULL|       NULL|    true|  [deleted]|          NULL|              NULL|                             |                  NULL|                 NULL|                    NULL|             NULL|                   dark|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|      true|          NULL|   false|        NULL|    NULL|   NULL|              NULL|       false|   NULL| 1230784330|            NULL|                 NULL|           NULL|         NULL|self.depression| NULL| false|NULL|   NULL|     NULL|     0|    NULL| false|     false|7mqur|                  NULL|            true|   NULL|               NULL|                 false|              NULL|   true|   false| NULL|                       NULL|                NULL|                 []|                  NULL|           NULL|                 dark|           text| false| NULL|{NULL, NULL, NULL...|      NULL|    NULL|         NULL|            NULL|       NULL|NULL|     true|           7|             0|       NULL|  false|                all_ads|/r/depression/com...|  NULL|           NULL|     NULL|   NULL|             NULL|           NULL|NULL|      NULL|          NULL|      NULL|               NULL|          NULL|  1522770247|         NULL|markdown| NULL|    6|        NULL|{NULL, NULL, NULL...|         |         NULL|        true|  false|   false|depression|    t5_2qqqf|           r/depression|                 NULL|        public|    confidence|     self|            NULL|           NULL|Nearly all of my ...|            NULL|                 NULL|          NULL|      NULL|NULL|        NULL|https://www.reddi...|                  NULL|        NULL|      NULL|   NULL|         all_ads|NULL|\n",
      "| NULL|         NULL|               NULL|           NULL|       NULL|    true|  [deleted]|          NULL|              NULL|                             |                  NULL|                 NULL|                    NULL|             NULL|                   dark|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|      true|          NULL|   false|        NULL|    NULL|   NULL|              NULL|       false|   NULL| 1230786778|            NULL|                 NULL|           NULL|         NULL|self.depression| NULL| false|NULL|   NULL|     NULL|     0|    NULL| false|     false|7mqyx|                  NULL|           false|   NULL|               NULL|                 false|              NULL|   true|   false| NULL|                       NULL|                NULL|                 []|                  NULL|           NULL|                 dark|           text| false| NULL|{NULL, NULL, NULL...|      NULL|    NULL|         NULL|            NULL|       NULL|NULL|     true|          11|             0|       NULL|  false|                all_ads|/r/depression/com...|  NULL|           NULL|     NULL|   NULL|             NULL|           NULL|NULL|      NULL|          NULL|      NULL|               NULL|          NULL|  1522770249|         NULL|markdown| NULL|    7|        NULL|{NULL, NULL, NULL...|[deleted]|         NULL|        true|  false|   false|depression|    t5_2qqqf|           r/depression|                 NULL|        public|    confidence|  default|            NULL|           NULL|I can't talk to g...|            NULL|                 NULL|          NULL|      NULL|NULL|        NULL|https://www.reddi...|                  NULL|        NULL|      NULL|   NULL|         all_ads|NULL|\n",
      "+-----+-------------+-------------------+---------------+-----------+--------+-----------+--------------+------------------+-----------------------------+----------------------+---------------------+------------------------+-----------------+-----------------------+-----------------+---------------+-----------------+--------------------+--------------+--------+-------------+---------+----------+--------------+--------+------------+--------+-------+------------------+------------+-------+-----------+----------------+---------------------+---------------+-------------+---------------+-----+------+----+-------+---------+------+--------+------+----------+-----+----------------------+----------------+-------+-------------------+----------------------+------------------+-------+--------+-----+---------------------------+--------------------+-------------------+----------------------+---------------+---------------------+---------------+------+-----+--------------------+----------+--------+-------------+----------------+-----------+----+---------+------------+--------------+-----------+-------+-----------------------+--------------------+------+---------------+---------+-------+-----------------+---------------+----+----------+--------------+----------+-------------------+--------------+------------+-------------+--------+-----+-----+------------+--------------------+---------+-------------+------------+-------+--------+----------+------------+-----------------------+---------------------+--------------+--------------+---------+----------------+---------------+--------------------+----------------+---------------------+--------------+----------+----+------------+--------------------+----------------------+------------+----------+-------+----------------+----+\n",
      "only showing top 5 rows\n",
      "+-----+-------------+---------------+-----------+--------+----------------+-----------+--------------+------------------+-----------------------------+----------------------+---------------------+------------------------+-----------------+-----------------------+-----------------+---------------+-----------------+--------------------+--------------+--------+-------------+---------+--------------------+---------+---------+--------+------------+---------+-------------------------------+----------------+---------------------+------------+----------------+-------+-----------+-------------+-----+--------+------+------+--------+----+------------+-----+--------+------+--------+-------------+----------------+-----------+-------+----------+---------+-----------+---------+---------+-----------+--------------+-------+--------------+------------+-------------+--------+-----+-----+------------+------------+---------------+--------+----------+------------+-----------------------+--------------+----------------+---------------------+--------------+------------------+----------+---+------------+\n",
      "|_meta|all_awardings|approved_at_utc|approved_by|archived|associated_award|     author|author_cakeday|author_created_utc|author_flair_background_color|author_flair_css_class|author_flair_richtext|author_flair_template_id|author_flair_text|author_flair_text_color|author_flair_type|author_fullname|author_is_blocked|author_patreon_flair|author_premium|awarders|banned_at_utc|banned_by|                body|body_html|body_sha1|can_gild|can_mod_post|collapsed|collapsed_because_crowd_control|collapsed_reason|collapsed_reason_code|comment_type|controversiality|created|created_utc|distinguished|downs|editable|edited|gilded|gildings|  id|is_submitter|likes| link_id|locked|mod_note|mod_reason_by|mod_reason_title|mod_reports|   name|nest_level|no_follow|num_reports|parent_id|permalink|quarantined|removal_reason|replies|report_reasons|retrieved_on|retrieved_utc|rte_mode|saved|score|score_hidden|send_replies|steward_reports|stickied| subreddit|subreddit_id|subreddit_name_prefixed|subreddit_type|top_awarded_type|total_awards_received|treatment_tags|unrepliable_reason|updated_on|ups|user_reports|\n",
      "+-----+-------------+---------------+-----------+--------+----------------+-----------+--------------+------------------+-----------------------------+----------------------+---------------------+------------------------+-----------------+-----------------------+-----------------+---------------+-----------------+--------------------+--------------+--------+-------------+---------+--------------------+---------+---------+--------+------------+---------+-------------------------------+----------------+---------------------+------------+----------------+-------+-----------+-------------+-----+--------+------+------+--------+----+------------+-----+--------+------+--------+-------------+----------------+-----------+-------+----------+---------+-----------+---------+---------+-----------+--------------+-------+--------------+------------+-------------+--------+-----+-----+------------+------------+---------------+--------+----------+------------+-----------------------+--------------+----------------+---------------------+--------------+------------------+----------+---+------------+\n",
      "| NULL|         NULL|           NULL|       NULL|    true|            NULL|HappyRabbit|          NULL|              NULL|                         NULL|                  NULL|                 NULL|                    NULL|             NULL|                   NULL|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|I have always bee...|     NULL|     NULL|    NULL|        NULL|     NULL|                           NULL|            NULL|                 NULL|        NULL|               0|   NULL| 1230776046|         NULL|    0|    NULL| false|     0|    NULL|7xa0|        NULL| NULL|t3_7mqdw|  NULL|    NULL|         NULL|            NULL|       NULL|t1_7xa0|      NULL|     NULL|       NULL| t3_7mqdw|     NULL|       NULL|          NULL|   NULL|          NULL|  1428222139|         NULL|    NULL| NULL|    1|       false|        NULL|           NULL|    NULL|depression|    t5_2qqqf|                   NULL|          NULL|            NULL|                 NULL|          NULL|              NULL|      NULL|  1|        NULL|\n",
      "| NULL|         NULL|           NULL|       NULL|    true|            NULL|  [deleted]|          NULL|              NULL|                         NULL|                  NULL|                 NULL|                    NULL|             NULL|                   NULL|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|Haha the picture ...|     NULL|     NULL|    NULL|        NULL|     NULL|                           NULL|            NULL|                 NULL|        NULL|               0|   NULL| 1230780294|         NULL|    0|    NULL| false|     0|    NULL|7y9n|        NULL| NULL|t3_7mqo7|  NULL|    NULL|         NULL|            NULL|       NULL|t1_7y9n|      NULL|     NULL|       NULL| t3_7mqo7|     NULL|       NULL|          NULL|   NULL|          NULL|  1428222152|         NULL|    NULL| NULL|    3|       false|        NULL|           NULL|    NULL|depression|    t5_2qqqf|                   NULL|          NULL|            NULL|                 NULL|          NULL|              NULL|      NULL|  3|        NULL|\n",
      "| NULL|         NULL|           NULL|       NULL|    true|            NULL|  [deleted]|          NULL|              NULL|                         NULL|                  NULL|                 NULL|                    NULL|             NULL|                   NULL|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|           [deleted]|     NULL|     NULL|    NULL|        NULL|     NULL|                           NULL|            NULL|                 NULL|        NULL|               0|   NULL| 1230786613|         NULL|    0|    NULL| false|     0|    NULL|7zel|        NULL| NULL|t3_7mqur|  NULL|    NULL|         NULL|            NULL|       NULL|t1_7zel|      NULL|     NULL|       NULL| t3_7mqur|     NULL|       NULL|          NULL|   NULL|          NULL|  1428222166|         NULL|    NULL| NULL|    1|       false|        NULL|           NULL|    NULL|depression|    t5_2qqqf|                   NULL|          NULL|            NULL|                 NULL|          NULL|              NULL|      NULL|  1|        NULL|\n",
      "| NULL|         NULL|           NULL|       NULL|    true|            NULL|     cluuxz|          NULL|              NULL|                         NULL|                  NULL|                 NULL|                    NULL|             NULL|                   NULL|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|It's like, I can ...|     NULL|     NULL|    NULL|        NULL|     NULL|                           NULL|            NULL|                 NULL|        NULL|               0|   NULL| 1230786885|         NULL|    0|    NULL| false|     0|    NULL|7zgf|        NULL| NULL|t3_7mqyx|  NULL|    NULL|         NULL|            NULL|       NULL|t1_7zgf|      NULL|     NULL|       NULL| t3_7mqyx|     NULL|       NULL|          NULL|   NULL|          NULL|  1428222167|         NULL|    NULL| NULL|    5|       false|        NULL|           NULL|    NULL|depression|    t5_2qqqf|                   NULL|          NULL|            NULL|                 NULL|          NULL|              NULL|      NULL|  5|        NULL|\n",
      "| NULL|         NULL|           NULL|       NULL|    true|            NULL|    cfabbro|          NULL|              NULL|                         NULL|                  NULL|                 NULL|                    NULL|             NULL|                   NULL|             NULL|           NULL|             NULL|                NULL|          NULL|    NULL|         NULL|     NULL|Do what makes you...|     NULL|     NULL|    NULL|        NULL|     NULL|                           NULL|            NULL|                 NULL|        NULL|               0|   NULL| 1230786916|         NULL|    0|    NULL|  true|     0|    NULL|7zgn|        NULL| NULL|t3_7mqur|  NULL|    NULL|         NULL|            NULL|       NULL|t1_7zgn|      NULL|     NULL|       NULL| t3_7mqur|     NULL|       NULL|          NULL|   NULL|          NULL|  1428222167|         NULL|    NULL| NULL|    6|       false|        NULL|           NULL|    NULL|depression|    t5_2qqqf|                   NULL|          NULL|            NULL|                 NULL|          NULL|              NULL|      NULL|  6|        NULL|\n",
      "+-----+-------------+---------------+-----------+--------+----------------+-----------+--------------+------------------+-----------------------------+----------------------+---------------------+------------------------+-----------------+-----------------------+-----------------+---------------+-----------------+--------------------+--------------+--------+-------------+---------+--------------------+---------+---------+--------+------------+---------+-------------------------------+----------------+---------------------+------------+----------------+-------+-----------+-------------+-----+--------+------+------+--------+----+------------+-----+--------+------+--------+-------------+----------------+-----------+-------+----------+---------+-----------+---------+---------+-----------+--------------+-------+--------------+------------+-------------+--------+-----+-----+------------+------------+---------------+--------+----------+------------+-----------------------+--------------+----------------+---------------------+--------------+------------------+----------+---+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "submissions = spark.read.json(\"depression_submissions\")\n",
    "comments = spark.read.json(\"depression_comments\")\n",
    "\n",
    "submissions.show(5)\n",
    "comments.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb1eaf",
   "metadata": {},
   "source": [
    "* Too many useless columns! \n",
    "* We pick what's important for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238321bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012301e",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd96686",
   "metadata": {},
   "source": [
    "### Comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3064abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------+---------+--------+-----+\n",
      "|  id|     author|created_utc|parent_id| link_id|score|\n",
      "+----+-----------+-----------+---------+--------+-----+\n",
      "|7xa0|HappyRabbit| 1230776046| t3_7mqdw|t3_7mqdw|    1|\n",
      "|7y9n|  [deleted]| 1230780294| t3_7mqo7|t3_7mqo7|    3|\n",
      "|7zel|  [deleted]| 1230786613| t3_7mqur|t3_7mqur|    1|\n",
      "|7zgf|     cluuxz| 1230786885| t3_7mqyx|t3_7mqyx|    5|\n",
      "|7zgn|    cfabbro| 1230786916| t3_7mqur|t3_7mqur|    6|\n",
      "|7zo9| Ostrich159| 1230788123| t3_7mqo7|t3_7mqo7|    6|\n",
      "|7zxq|redmosquito| 1230789682|  t1_7zgf|t3_7mqyx|    3|\n",
      "|7zyg|    simmias| 1230789820| t3_7mqur|t3_7mqur|    7|\n",
      "|802k|      Sawta| 1230790554| t3_7mqyx|t3_7mqyx|    6|\n",
      "|813r| Ostrich159| 1230796786|  t1_7zgf|t3_7mqyx|    4|\n",
      "+----+-----------+-----------+---------+--------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "comments = comments.select(\"id\", \"author\", \"created_utc\", \"parent_id\", \"link_id\", \"score\")\n",
    "comments.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f34d",
   "metadata": {},
   "source": [
    "We see that:\n",
    "* direct comment to the post have the same link_id and parent_id starting with \"t3_\"\n",
    "* replies to other comments have a parent_id starting with \"t1_\" and ends with the id of the parent comment\n",
    "* we can use the parent_id prefix type and get red of the the columns link_id and score\n",
    "* for embedded comments we know the author of the parent comment but for direct comments we dont know the submitter that they are interracted with\n",
    "* we can join with the submissions to get that information and build our graph\n",
    "* for the created_utc column we need to transform it into something human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf8894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================================>        (168 + 24) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------+----------+----+-----+---+\n",
      "|     id|           author|created_utc| parent_id|year|month|day|\n",
      "+-------+-----------------+-----------+----------+----+-----+---+\n",
      "|m4rvixo|      fmylife2024| 1735689484|t1_m4rv20i|2025|    1|  1|\n",
      "|m4rv3xo|     Unreal_catto| 1735689327|t3_1hqevuc|2025|    1|  1|\n",
      "|m4rv20i|Fabulous_Owl_8471| 1735689307|t1_m4ruqba|2025|    1|  1|\n",
      "|m4rv1ox|        [deleted]| 1735689304|t3_1frqlk0|2025|    1|  1|\n",
      "|m4ruqba|      fmylife2024| 1735689184|t1_m4rrqqh|2025|    1|  1|\n",
      "|m4ru0xd|     Nutsyblazzer| 1735688918|t1_m4r70da|2025|    1|  1|\n",
      "|m4rtwm7| Single_Berry7546| 1735688872|t1_m4rpwi1|2025|    1|  1|\n",
      "|m4rtuzw|Fabulous_Owl_8471| 1735688855|t3_1hqnkkr|2025|    1|  1|\n",
      "|m4rtm0a| Single_Berry7546| 1735688761|t1_m4rm736|2025|    1|  1|\n",
      "|m4rthad|   tarteframboise| 1735688712|t3_1hqqtay|2025|    1|  1|\n",
      "+-------+-----------------+-----------+----------+----+-----+---+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Deleting the link_id and score columns\n",
    "comments = comments.select(\"id\", \"author\", \"created_utc\", \"parent_id\")\n",
    "\n",
    "# transforming the created_utc column\n",
    "# first we cast the column into a long\n",
    "comments = comments.withColumn(\"created_utc\", F.col(\"created_utc\").cast(\"double\").cast(\"long\"))\n",
    "\n",
    "comments = comments.withColumn(\"year\", F.year(F.from_unixtime(\"created_utc\").cast(\"timestamp\"))) \\\n",
    "       .withColumn(\"month\", F.month(F.from_unixtime(\"created_utc\").cast(\"timestamp\"))) \\\n",
    "       .withColumn(\"day\", F.dayofmonth(F.from_unixtime(\"created_utc\").cast(\"timestamp\")))\n",
    "\n",
    "comments.orderBy(F.col(\"created_utc\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ecf72b",
   "metadata": {},
   "source": [
    "### Submissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5474df0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+-----+------------+\n",
      "|   id|     author|created_utc|score|num_comments|\n",
      "+-----+-----------+-----------+-----+------------+\n",
      "|7mqco|  [deleted]| 1230773002|    1|           0|\n",
      "|7mqdw|HappyRabbit| 1230773772|    1|           1|\n",
      "|7mqo7|  [deleted]| 1230780179|    7|           2|\n",
      "|7mqur|  [deleted]| 1230784330|    6|           7|\n",
      "|7mqyx|  [deleted]| 1230786778|    7|          11|\n",
      "|7mr2a| Ostrich159| 1230788514|    4|           0|\n",
      "|7mrbw|  [deleted]| 1230794035|    7|           1|\n",
      "|7mrg3|  [deleted]| 1230796700|    9|           7|\n",
      "|7mrp0| OctopusMan| 1230802690|   12|          14|\n",
      "|7mru2|   i_love_u| 1230806086|    1|           0|\n",
      "+-----+-----------+-----------+-----+------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "submissions = submissions.select(\"id\", \"author\", \"created_utc\", \"score\", \"num_comments\")\n",
    "submissions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6e294",
   "metadata": {},
   "source": [
    "* For the submissions we dont need the columns created_utc, score, num_comments\n",
    "* the dataframe is needed only for joining to find the submission author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3230f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|   id|     author|\n",
      "+-----+-----------+\n",
      "|7mqco|  [deleted]|\n",
      "|7mqdw|HappyRabbit|\n",
      "|7mqo7|  [deleted]|\n",
      "|7mqur|  [deleted]|\n",
      "|7mqyx|  [deleted]|\n",
      "+-----+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "submissions = submissions.select(\"id\", \"author\")\n",
    "submissions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66207ea",
   "metadata": {},
   "source": [
    "### Graph dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f37dcd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==================================================>   (187 + 13) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+----------------+----+-----+---+\n",
      "|       source|             target| timestamp|interaction_type|year|month|day|\n",
      "+-------------+-------------------+----------+----------------+----+-----+---+\n",
      "| DedInside50s|         27Club2023|1672533471| comment_on_post|2023|    1|  1|\n",
      "| youlackfacts|         27Club2023|1672534825| comment_on_post|2023|    1|  1|\n",
      "|   Weary-Lime|Hatelovedemonslayer|1672543313| comment_on_post|2023|    1|  1|\n",
      "|radish_recoup|Hatelovedemonslayer|1672579363| comment_on_post|2023|    1|  1|\n",
      "|    irinirinn|         sad_apple5|1672565992| comment_on_post|2023|    1|  1|\n",
      "+-------------+-------------------+----------+----------------+----+-----+---+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "comments_to_posts = comments.filter(F.col(\"parent_id\").startswith(\"t3_\")) \\\n",
    "    .withColumn(\"post_id\", F.regexp_replace(F.col(\"parent_id\"), \"^t3_\", \"\")) \\\n",
    "    .join(submissions, F.col(\"post_id\") == submissions[\"id\"], \"inner\") \\\n",
    "    .select(\n",
    "        comments[\"author\"].alias(\"source\"),\n",
    "        submissions[\"author\"].alias(\"target\"),\n",
    "        comments[\"created_utc\"].alias(\"timestamp\"),\n",
    "        F.lit(\"comment_on_post\").alias(\"interaction_type\"),\n",
    "        comments[\"year\"],\n",
    "        comments[\"month\"],\n",
    "        comments[\"day\"]\n",
    "    )\n",
    "\n",
    "comments_to_posts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e79712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:================================================>    (184 + 16) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------+------------------+----+-----+---+\n",
      "|    source|        target| timestamp|  interaction_type|year|month|day|\n",
      "+----------+--------------+----------+------------------+----+-----+---+\n",
      "| [deleted]|IheartDaRegion|1237915656|comment_on_comment|2009|    3| 24|\n",
      "| [deleted]|      bluegerm|1254096044|comment_on_comment|2009|    9| 28|\n",
      "|sickasabat|     [deleted]|1266596772|comment_on_comment|2010|    2| 19|\n",
      "|    soitis|        mvoewf|1267353088|comment_on_comment|2010|    2| 28|\n",
      "| [deleted]|        rymmen|1270956588|comment_on_comment|2010|    4| 11|\n",
      "+----------+--------------+----------+------------------+----+-----+---+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "comment_replies = comments.filter(F.col(\"parent_id\").startswith(\"t1_\")) \\\n",
    "    .withColumn(\"parent_comment_id\", F.regexp_replace(F.col(\"parent_id\"), \"^t1_\", \"\")) \\\n",
    "    .alias(\"c1\") \\\n",
    "    .join(comments.alias(\"c2\"), F.col(\"c1.parent_comment_id\") == F.col(\"c2.id\"), \"inner\") \\\n",
    "    .select(\n",
    "        F.col(\"c1.author\").alias(\"source\"),\n",
    "        F.col(\"c2.author\").alias(\"target\"),\n",
    "        F.col(\"c1.created_utc\").alias(\"timestamp\"),\n",
    "        F.lit(\"comment_on_comment\").alias(\"interaction_type\"),\n",
    "        F.col(\"c1.year\"),\n",
    "        F.col(\"c1.month\"),\n",
    "        F.col(\"c1.day\")\n",
    "    )\n",
    "\n",
    "comment_replies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475b66a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=================================>                   (190 + 24) / 300]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------+------------------+----+-----+---+\n",
      "|       source|    target| timestamp|  interaction_type|year|month|day|\n",
      "+-------------+----------+----------+------------------+----+-----+---+\n",
      "|  redmosquito|    cluuxz|1230789682|comment_on_comment|2009|    1|  1|\n",
      "|   Ostrich159|    cluuxz|1230796786|comment_on_comment|2009|    1|  1|\n",
      "|     cujo3017|    cluuxz|1230800681|comment_on_comment|2009|    1|  1|\n",
      "|bobkingof12vs|OctopusMan|1230805754|comment_on_comment|2009|    1|  1|\n",
      "|bobkingof12vs|  i_love_u|1230807596|   comment_on_post|2009|    1|  1|\n",
      "|     g2petter|OctopusMan|1230812559|comment_on_comment|2009|    1|  1|\n",
      "|   julenissen|OctopusMan|1230816912|comment_on_comment|2009|    1|  1|\n",
      "|      lemming|OctopusMan|1230833115|comment_on_comment|2009|    1|  1|\n",
      "|         mmmf|    cluuxz|1230845741|comment_on_comment|2009|    1|  1|\n",
      "|ThatOtherGirl|OctopusMan|1231130231|comment_on_comment|2009|    1|  5|\n",
      "+-------------+----------+----------+------------------+----+-----+---+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "edges = comments_to_posts.union(comment_replies) \\\n",
    "    .filter((F.col(\"source\") != \"[deleted]\") & (F.col(\"target\") != \"[deleted]\") & (F.col(\"source\") != F.col(\"target\")) & (F.col(\"year\") < 2025)) \\\n",
    "    .orderBy(\"timestamp\")\n",
    "\n",
    "edges.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08b29f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f315b5",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72ba828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:============================>                        (159 + 24) / 300]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 6377886\n",
      "After filtering deleted users: 4116812\n",
      "Deleted interactions: 2261074\n",
      "Deleted percentage: 35.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cmt_on_cmt_count = comment_replies.count()\n",
    "cmt_on_pst_count = comments_to_posts.count()\n",
    "\n",
    "total = cmt_on_cmt_count + cmt_on_pst_count\n",
    "final = edges.count()\n",
    "deleted = total - final  \n",
    "deleted_prct = (deleted/total)*100\n",
    "\n",
    "print(f\"Total interactions: {total}\")\n",
    "print(f\"After filtering deleted users: {final}\")\n",
    "print(f\"Deleted interactions: {deleted}\")\n",
    "print(f\"Deleted percentage: {deleted_prct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3489fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics per year using Spark\n",
    "yearly_stats = edges.groupBy('year').agg(\n",
    "    F.count('*').alias('num_edges'),\n",
    "    F.countDistinct('source').alias('num_sources'),\n",
    "    F.countDistinct('target').alias('num_targets'),\n",
    "    F.countDistinct(F.concat('source', 'target')).alias('unique_pairs')\n",
    ").orderBy('year')\n",
    "\n",
    "# Compute total unique users per year (union of sources and targets)\n",
    "users_per_year = edges.groupBy('year').agg(\n",
    "    F.countDistinct(F.array('source', 'target')).alias('temp')\n",
    ")\n",
    "\n",
    "# Better approach: union sources and targets\n",
    "sources = edges.select('year', F.col('source').alias('user'))\n",
    "targets = edges.select('year', F.col('target').alias('user'))\n",
    "unique_users_per_year = sources.union(targets)\\\n",
    "    .groupBy('year')\\\n",
    "    .agg(F.countDistinct('user').alias('num_unique_users'))\\\n",
    "    .orderBy('year')\n",
    "\n",
    "# Join the statistics\n",
    "yearly_stats = yearly_stats.join(unique_users_per_year, on='year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af16738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly Statistics Preview:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----------+-----------+------------+----------------+\n",
      "|year|num_edges|num_sources|num_targets|unique_pairs|num_unique_users|\n",
      "+----+---------+-----------+-----------+------------+----------------+\n",
      "|2009|721      |213        |173        |549         |255             |\n",
      "|2010|8525     |2145       |1798       |6721        |2551            |\n",
      "|2011|27164    |6895       |5914       |21977       |8342            |\n",
      "|2012|91852    |19695      |16982      |71668       |23557           |\n",
      "|2013|132251   |31438      |27466      |102740      |38167           |\n",
      "|2014|159839   |38317      |34686      |124411      |46941           |\n",
      "|2015|258452   |52956      |47995      |205018      |64216           |\n",
      "|2016|340632   |63587      |55676      |275469      |76105           |\n",
      "|2017|459203   |78518      |67434      |362710      |92700           |\n",
      "|2018|501110   |96115      |81217      |396571      |113274          |\n",
      "|2019|568433   |119209     |98910      |449891      |140128          |\n",
      "|2020|429705   |104513     |87521      |335407      |124622          |\n",
      "|2021|298801   |82602      |69129      |240037      |100179          |\n",
      "|2022|245621   |71411      |60263      |201117      |88218           |\n",
      "|2023|245701   |68041      |54239      |206253      |83232           |\n",
      "|2024|348802   |93743      |72191      |291894      |112788          |\n",
      "+----+---------+-----------+-----------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show sample\n",
    "print(\"Yearly Statistics Preview:\")\n",
    "yearly_stats.orderBy(\"year\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faef964",
   "metadata": {},
   "source": [
    "### General statistics visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5c215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPLETE YEARLY STATISTICS\n",
      "================================================================================\n",
      " year  num_edges  num_sources  num_targets  unique_pairs  num_unique_users  avg_degree  density  density_pct\n",
      " 2009        721          213          173           549               255    5.654902 0.011132     1.113170\n",
      " 2010       8525         2145         1798          6721              2551    6.683653 0.001311     0.131052\n",
      " 2011      27164         6895         5914         21977              8342    6.512587 0.000390     0.039040\n",
      " 2012      91852        19695        16982         71668             23557    7.798277 0.000166     0.016553\n",
      " 2013     132251        31438        27466        102740             38167    6.930123 0.000091     0.009079\n",
      " 2014     159839        38317        34686        124411             46941    6.810209 0.000073     0.007254\n",
      " 2015     258452        52956        47995        205018             64216    8.049458 0.000063     0.006268\n",
      " 2016     340632        63587        55676        275469             76105    8.951633 0.000059     0.005881\n",
      " 2017     459203        78518        67434        362710             92700    9.907292 0.000053     0.005344\n",
      " 2018     501110        96115        81217        396571            113274    8.847750 0.000039     0.003905\n",
      " 2019     568433       119209        98910        449891            140128    8.113054 0.000029     0.002895\n",
      " 2020     429705       104513        87521        335407            124622    6.896134 0.000028     0.002767\n",
      " 2021     298801        82602        69129        240037            100179    5.965342 0.000030     0.002977\n",
      " 2022     245621        71411        60263        201117             88218    5.568501 0.000032     0.003156\n",
      " 2023     245701        68041        54239        206253             83232    5.904003 0.000035     0.003547\n",
      " 2024     348802        93743        72191        291894            112788    6.185091 0.000027     0.002742\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Collect to Pandas (small data - only 17 rows)\n",
    "df_yearly = yearly_stats.toPandas()\n",
    "df_yearly = df_yearly.sort_values(\"year\").reset_index(drop=True)\n",
    "# Calculate derived metrics\n",
    "df_yearly['avg_degree'] = (2 * df_yearly['num_edges']) / df_yearly['num_unique_users']\n",
    "df_yearly['density'] = df_yearly['num_edges'] / (df_yearly['num_unique_users'] * (df_yearly['num_unique_users'] - 1))\n",
    "\n",
    "# Format density as percentage for readability\n",
    "df_yearly['density_pct'] = df_yearly['density'] * 100\n",
    "\n",
    "# Display the complete table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE YEARLY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(df_yearly.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9605512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization saved as 'network_evolution_overview.png'\n"
     ]
    }
   ],
   "source": [
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Network Growth (Nodes and Edges)\n",
    "ax1 = axes[0, 0]\n",
    "ax1_twin = ax1.twinx()\n",
    "\n",
    "ax1.plot(df_yearly['year'], df_yearly['num_unique_users'], \n",
    "         marker='o', linewidth=2, markersize=6, color='#2E86AB', label='Unique Users')\n",
    "ax1_twin.plot(df_yearly['year'], df_yearly['num_edges'], \n",
    "              marker='s', linewidth=2, markersize=6, color='#A23B72', label='Edges')\n",
    "\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Number of Unique Users', fontsize=12, color='#2E86AB')\n",
    "ax1_twin.set_ylabel('Number of Edges', fontsize=12, color='#A23B72')\n",
    "ax1.tick_params(axis='y', labelcolor='#2E86AB')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='#A23B72')\n",
    "ax1.set_title('Network Growth Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1_twin.legend(loc='upper right')\n",
    "\n",
    "# Plot 2: Density Evolution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(df_yearly['year'], df_yearly['density_pct'], \n",
    "         marker='o', linewidth=2, markersize=6, color='#F18F01')\n",
    "ax2.set_xlabel('Year', fontsize=12)\n",
    "ax2.set_ylabel('Density (%)', fontsize=12)\n",
    "ax2.set_title('Network Density Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Average Degree\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(df_yearly['year'], df_yearly['avg_degree'], \n",
    "         marker='o', linewidth=2, markersize=6, color='#6A994E')\n",
    "ax3.set_xlabel('Year', fontsize=12)\n",
    "ax3.set_ylabel('Average Degree', fontsize=12)\n",
    "ax3.set_title('Average Degree Over Time', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Year-over-Year Growth Rate\n",
    "ax4 = axes[1, 1]\n",
    "df_yearly['edge_growth_pct'] = df_yearly['num_edges'].pct_change() * 100\n",
    "df_yearly['user_growth_pct'] = df_yearly['num_unique_users'].pct_change() * 100\n",
    "\n",
    "ax4.bar(df_yearly['year'][1:], df_yearly['edge_growth_pct'][1:], \n",
    "        alpha=0.7, label='Edge Growth %', color='#A23B72')\n",
    "ax4.bar(df_yearly['year'][1:], df_yearly['user_growth_pct'][1:], \n",
    "        alpha=0.7, label='User Growth %', color=\"#2E86AB\")\n",
    "ax4.set_xlabel('Year', fontsize=12)\n",
    "ax4.set_ylabel('Growth Rate (%)', fontsize=12)\n",
    "ax4.set_title('Year-over-Year Growth Rates', fontsize=14, fontweight='bold')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('network_evolution_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved as 'network_evolution_overview.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8455b6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70836efe",
   "metadata": {},
   "source": [
    "## Yearly graph snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7eb3cb",
   "metadata": {},
   "source": [
    "### Graphs directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3493df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created: yearly_graphs/\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'yearly_graphs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory created: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355f0b4",
   "metadata": {},
   "source": [
    "### Graph export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a161994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting export of yearly edge lists...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2009: 721 edges exported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2010: 8,525 edges exported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2011: 27,164 edges exported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2012: 91,852 edges exported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.0][Stage 307:>(0 + 0) / 200]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sora/Git/reddit-depression-dynamic-graph-analysis/.venv/lib/python3.13/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/sora/Git/reddit-depression-dynamic-graph-analysis/.venv/lib/python3.13/site-packages/py4j/clientserver.py\", line 535, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/lib/python3.13/socket.py\", line 719, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^\n",
      "KeyboardInterrupt\n",
      "[Stage 305:(137 + 24) / 200][Stage 306:>(0 + 0) / 200][Stage 307:>(0 + 0) / 200]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m year_edges = edges.filter(F.col(\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m) == year)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Edge count\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m edge_count = \u001b[43myear_edges\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Important columns selection\u001b[39;00m\n\u001b[32m     16\u001b[39m year_edges.select(\u001b[33m'\u001b[39m\u001b[33msource\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minteraction_type\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     17\u001b[39m     .coalesce(\u001b[32m1\u001b[39m) \\\n\u001b[32m     18\u001b[39m     .write.mode(\u001b[33m'\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     19\u001b[39m     .option(\u001b[33m'\u001b[39m\u001b[33mheader\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     20\u001b[39m     .csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/temp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/reddit-depression-dynamic-graph-analysis/.venv/lib/python3.13/site-packages/pyspark/sql/classic/dataframe.py:439\u001b[39m, in \u001b[36mDataFrame.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/reddit-depression-dynamic-graph-analysis/.venv/lib/python3.13/site-packages/py4j/java_gateway.py:1361\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1354\u001b[39m args_command, temp_args = \u001b[38;5;28mself\u001b[39m._build_args(*args)\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m return_value = get_return_value(\n\u001b[32m   1363\u001b[39m     answer, \u001b[38;5;28mself\u001b[39m.gateway_client, \u001b[38;5;28mself\u001b[39m.target_id, \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/reddit-depression-dynamic-graph-analysis/.venv/lib/python3.13/site-packages/py4j/java_gateway.py:1038\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1036\u001b[39m connection = \u001b[38;5;28mself\u001b[39m._get_connection()\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[32m   1040\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m._create_connection_guard(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/reddit-depression-dynamic-graph-analysis/.venv/lib/python3.13/site-packages/py4j/clientserver.py:535\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         answer = smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:-\u001b[32m1\u001b[39m])\n\u001b[32m    536\u001b[39m         logger.debug(\u001b[33m\"\u001b[39m\u001b[33mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m\"\u001b[39m.format(answer))\n\u001b[32m    537\u001b[39m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[32m    538\u001b[39m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 305:(150 + 24) / 200][Stage 306:>(0 + 0) / 200][Stage 307:>(0 + 0) / 200]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 308:===============================================>    (181 + 19) / 200]\r"
     ]
    }
   ],
   "source": [
    "years_to_export = range(2009, 2025) # from 2009 to 2024\n",
    "\n",
    "print(\"Starting export of yearly edge lists...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "export_summary = []\n",
    "\n",
    "for year in years_to_export:\n",
    "    # Filter by year\n",
    "    year_edges = edges.filter(F.col('year') == year)\n",
    "    \n",
    "    # Edge count\n",
    "    edge_count = year_edges.count()\n",
    "    \n",
    "    # Important columns selection\n",
    "    year_edges.select('source', 'target', 'timestamp', 'interaction_type') \\\n",
    "        .coalesce(1) \\\n",
    "        .write.mode('overwrite') \\\n",
    "        .option('header', 'true') \\\n",
    "        .csv(f'{output_dir}/temp_{year}')\n",
    "    \n",
    "    # Summary\n",
    "    export_summary.append({\n",
    "        'year': year,\n",
    "        'edges': edge_count\n",
    "    })\n",
    "    \n",
    "    print(f\"Year {year}: {edge_count:,} edges exported\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"All years exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dc2e9",
   "metadata": {},
   "source": [
    "### Optional renaming:\n",
    "\n",
    "Spark doesn't save dataframes with cleanly like pandas so we need to do all the work manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead2788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning up file structure...\n",
      "File structure cleaned up!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCleaning up file structure...\")\n",
    "\n",
    "for year in years_to_export:\n",
    "    temp_dir = f'{output_dir}/temp_{year}'\n",
    "    \n",
    "    # Find the actual CSV file (Spark names it part-xxxxx.csv)\n",
    "    csv_files = glob.glob(f'{temp_dir}/part-*.csv')\n",
    "    \n",
    "    if csv_files:\n",
    "        # Rename to clean filename\n",
    "        final_filename = f'{output_dir}/edges_{year}.csv'\n",
    "        shutil.move(csv_files[0], final_filename)\n",
    "        \n",
    "        # Remove temp directory\n",
    "        shutil.rmtree(temp_dir)\n",
    "        \n",
    "print(\"File structure cleaned up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557eaeb2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fc974",
   "metadata": {},
   "source": [
    "# Graph Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a463e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph for year 2019...\n",
      "Loaded 568,433 edges from yearly_graphs/edges_2019.csv\n",
      "Graph created successfully!\n",
      "   Nodes: 140,128\n",
      "   Edges: 568,433\n"
     ]
    }
   ],
   "source": [
    "# Choose test year\n",
    "test_year = 2019\n",
    "\n",
    "print(f\"Loading graph for year {test_year}...\")\n",
    "\n",
    "# Load edge list from CSV\n",
    "edges_file = f'yearly_graphs/edges_{test_year}.csv'\n",
    "df_edges = pd.read_csv(edges_file)\n",
    "\n",
    "print(f\"Loaded {len(df_edges):,} edges from {edges_file}\")\n",
    "\n",
    "# Create igraph from edge list\n",
    "# tuples parameter: list of (source, target) tuples\n",
    "# directed=True: because comments have direction (commenter  recipient)\n",
    "edge_tuples = list(zip(df_edges['source'], df_edges['target']))\n",
    "\n",
    "G = ig.Graph.TupleList(edge_tuples, directed=True)\n",
    "\n",
    "print(f\"Graph created successfully!\")\n",
    "print(f\"   Nodes: {G.vcount():,}\")\n",
    "print(f\"   Edges: {G.ecount():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939b529",
   "metadata": {},
   "source": [
    "*=>* Note that i have picked a single year for test (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99555abb",
   "metadata": {},
   "source": [
    "### Basic Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5917d685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NETWORK METRICS FOR YEAR 2019\n",
      "================================================================================\n",
      "\n",
      "# BASIC STATISTICS:\n",
      "   Nodes (users): 140,128\n",
      "   Edges (interactions): 568,433\n",
      "   Density: 0.000029 (0.0029%)\n",
      "   Directed: True\n",
      "\n",
      "# CONNECTIVITY:\n",
      "   Number of components: 2297\n",
      "   Giant component size: 135,203 nodes (96.5%)\n",
      "   Isolated nodes: 0\n",
      "\n",
      "# DEGREE STATISTICS:\n",
      "   Average out-degree: 4.06\n",
      "   Average in-degree: 4.06\n",
      "   Average total degree: 8.11\n",
      "   Max out-degree: 4683 (most active commenter)\n",
      "   Max in-degree: 5166 (most replied-to user)\n",
      "\n",
      "# CLUSTERING:\n",
      "   Global transitivity: 0.003087\n",
      "   Average local clustering: 0.042312\n",
      "\n",
      "# RECIPROCITY:\n",
      "   Reciprocity: 0.472246 (47.22% of edges are reciprocated)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"NETWORK METRICS FOR YEAR {test_year}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Basic statistics\n",
    "num_nodes = G.vcount()\n",
    "num_edges = G.ecount()\n",
    "density = G.density()\n",
    "\n",
    "print(f\"\\n# BASIC STATISTICS:\")\n",
    "print(f\"   Nodes (users): {num_nodes:,}\")\n",
    "print(f\"   Edges (interactions): {num_edges:,}\")\n",
    "print(f\"   Density: {density:.6f} ({density*100:.4f}%)\")\n",
    "print(f\"   Directed: {G.is_directed()}\")\n",
    "\n",
    "# Connected components\n",
    "components = G.connected_components(mode='weak')  # weak = ignore direction\n",
    "num_components = len(components)\n",
    "giant_component_size = max(components.sizes())\n",
    "\n",
    "print(f\"\\n# CONNECTIVITY:\")\n",
    "print(f\"   Number of components: {num_components}\")\n",
    "print(f\"   Giant component size: {giant_component_size:,} nodes ({giant_component_size/num_nodes*100:.1f}%)\")\n",
    "print(f\"   Isolated nodes: {sum(1 for size in components.sizes() if size == 1)}\")\n",
    "\n",
    "# Degree statistics\n",
    "degrees_out = G.degree(mode='out')  # out-degree: how many people they comment to\n",
    "degrees_in = G.degree(mode='in')    # in-degree: how many people comment to them\n",
    "degrees_all = G.degree(mode='all')  # total degree\n",
    "\n",
    "print(f\"\\n# DEGREE STATISTICS:\")\n",
    "print(f\"   Average out-degree: {np.mean(degrees_out):.2f}\")\n",
    "print(f\"   Average in-degree: {np.mean(degrees_in):.2f}\")\n",
    "print(f\"   Average total degree: {np.mean(degrees_all):.2f}\")\n",
    "print(f\"   Max out-degree: {max(degrees_out)} (most active commenter)\")\n",
    "print(f\"   Max in-degree: {max(degrees_in)} (most replied-to user)\")\n",
    "\n",
    "# Clustering coefficient (computationally expensive, so we'll use transitivity)\n",
    "transitivity = G.transitivity_undirected()\n",
    "avg_clustering = G.transitivity_avglocal_undirected()\n",
    "\n",
    "print(f\"\\n# CLUSTERING:\")\n",
    "print(f\"   Global transitivity: {transitivity:.6f}\")\n",
    "print(f\"   Average local clustering: {avg_clustering:.6f}\")\n",
    "\n",
    "# Reciprocity (for directed graphs - mutual connections)\n",
    "reciprocity = G.reciprocity()\n",
    "print(f\"\\n# RECIPROCITY:\")\n",
    "print(f\"   Reciprocity: {reciprocity:.6f} ({reciprocity*100:.2f}% of edges are reciprocated)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd15d7",
   "metadata": {},
   "source": [
    "### Centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd0d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CENTRALITY ANALYSIS - TOP INFLUENTIAL USERS\n",
      "================================================================================\n",
      "\n",
      "# TOP 10 USERS BY OUT-DEGREE (Most Active Commenters):\n",
      "    1. AnotherTrowaway12              -  4683 comments made\n",
      "    2. JesusAndSoda                   -  4161 comments made\n",
      "    3. maddiokii                      -   722 comments made\n",
      "    4. EnnazusCB                      -   681 comments made\n",
      "    5. What_I_do_45                   -   608 comments made\n",
      "    6. StrongCrypto                   -   603 comments made\n",
      "    7. treatment32                    -   583 comments made\n",
      "    8. numberfivedream                -   573 comments made\n",
      "    9. gibsonh90                      -   512 comments made\n",
      "   10. Juancervantes22                -   503 comments made\n",
      "\n",
      "# TOP 10 USERS BY IN-DEGREE (Most Replied-To):\n",
      "    1. SQLwitch                       -  5166 comments received\n",
      "    2. circinia                       -  3989 comments received\n",
      "    3. AnotherTrowaway12              -  2775 comments received\n",
      "    4. JesusAndSoda                   -  2489 comments received\n",
      "    5. Kin9582                        -  1170 comments received\n",
      "    6. ThisNotMyMainAcc               -   741 comments received\n",
      "    7. drauch52                       -   734 comments received\n",
      "    8. aightaight_                    -   670 comments received\n",
      "    9. witchofthewoods89              -   574 comments received\n",
      "   10. What_I_do_45                   -   541 comments received\n",
      "\n",
      "# TOP 10 USERS BY PAGERANK (Overall Influence):\n",
      "    1. SQLwitch                       - PageRank: 0.005848\n",
      "    2. circinia                       - PageRank: 0.004594\n",
      "    3. JesusAndSoda                   - PageRank: 0.003720\n",
      "    4. AnotherTrowaway12              - PageRank: 0.003482\n",
      "    5. aightaight_                    - PageRank: 0.002387\n",
      "    6. anonymisslou4                  - PageRank: 0.002031\n",
      "    7. Kin9582                        - PageRank: 0.001869\n",
      "    8. drauch52                       - PageRank: 0.000897\n",
      "    9. ThisNotMyMainAcc               - PageRank: 0.000838\n",
      "   10. witchofthewoods89              - PageRank: 0.000788\n",
      "\n",
      "=>  Betweenness centrality skipped (computationally expensive for 140k nodes)\n",
      "   Will compute for smaller years or on a sample\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CENTRALITY ANALYSIS - TOP INFLUENTIAL USERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get node names\n",
    "node_names = G.vs['name']\n",
    "\n",
    "# 1. Degree Centrality (most active/popular)\n",
    "print(\"\\n# TOP 10 USERS BY OUT-DEGREE (Most Active Commenters):\")\n",
    "degree_out = G.degree(mode='out')\n",
    "top_out = sorted(zip(node_names, degree_out), key=lambda x: x[1], reverse=True)[:10]\n",
    "for i, (user, deg) in enumerate(top_out, 1):\n",
    "    print(f\"   {i:2d}. {user:30s} - {deg:5d} comments made\")\n",
    "\n",
    "print(\"\\n# TOP 10 USERS BY IN-DEGREE (Most Replied-To):\")\n",
    "degree_in = G.degree(mode='in')\n",
    "top_in = sorted(zip(node_names, degree_in), key=lambda x: x[1], reverse=True)[:10]\n",
    "for i, (user, deg) in enumerate(top_in, 1):\n",
    "    print(f\"   {i:2d}. {user:30s} - {deg:5d} comments received\")\n",
    "\n",
    "# 2. PageRank (overall influence)\n",
    "print(\"\\n# TOP 10 USERS BY PAGERANK (Overall Influence):\")\n",
    "pagerank = G.pagerank()\n",
    "top_pr = sorted(zip(node_names, pagerank), key=lambda x: x[1], reverse=True)[:10]\n",
    "for i, (user, pr) in enumerate(top_pr, 1):\n",
    "    print(f\"   {i:2d}. {user:30s} - PageRank: {pr:.6f}\")\n",
    "\n",
    "# 3. Betweenness Centrality (bridges/connectors)\n",
    "# Note: This is expensive, so we'll compute for a sample \n",
    "print(\"\\n=>  Betweenness centrality skipped (computationally expensive for 140k nodes)\")\n",
    "print(\"   Will compute for smaller years or on a sample\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BETWEENESS CENTRALITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "\n",
    "# Approximate betweenness with cutoff\n",
    "print(\"\\nComputing approximate betweenness (cutoff=5)...\")\n",
    "start_time = time.time()\n",
    "betweenness = G.betweenness(directed=True, cutoff=5)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"=> Betweenness computed in {elapsed:.1f} seconds\")\n",
    "\n",
    "# 3. Find top nodes\n",
    "top_n = 10\n",
    "top_betweenness_idx = sorted(range(num_nodes), key=lambda x: betweenness[x], reverse=True)[:top_n]\n",
    "\n",
    "print(f\"\\n# Top {top_n} Most Central Nodes:\")\n",
    "\n",
    "\n",
    "print(f\"\\nBy Betweenness (bridge position):\")\n",
    "for i, idx in enumerate(top_betweenness_idx, 1):\n",
    "    print(f\"  {i}. Node {idx}: {betweenness[idx]:.2f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e12c2",
   "metadata": {},
   "source": [
    "### Community detection (lovain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5073aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMMUNITY DETECTION (Louvain Algorithm)\n",
      "================================================================================\n",
      "Running Louvain algorithm (this may take 1-2 minutes)...\n",
      "\n",
      "=>Community detection complete!\n",
      "\n",
      "# COMMUNITY STATISTICS:\n",
      "   Number of communities: 2599\n",
      "   Modularity: 0.5183\n",
      "   Largest community: 27,391 members\n",
      "   Smallest community: 2 members\n",
      "   Average community size: 53.9\n",
      "\n",
      "# COMMUNITY SIZE DISTRIBUTION:\n",
      "          1-9 members: 2515 communities\n",
      "        10-49 members:   45 communities\n",
      "        50-99 members:    1 communities\n",
      "      100-499 members:   13 communities\n",
      "      500-999 members:   17 communities\n",
      "    1000-4999 members:    1 communities\n",
      "        5000+ members:    7 communities\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMMUNITY DETECTION (Louvain Algorithm)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run Louvain community detection\n",
    "# Using undirected version for community detection (more standard)\n",
    "print(\"Running Louvain algorithm (this may take 1-2 minutes)...\")\n",
    "\n",
    "\n",
    "# Note that i turned the graph into an undirected one\n",
    "G_undirected = G.as_undirected(mode=\"collapse\", combine_edges=\"sum\")\n",
    "communities = G_undirected.community_multilevel()\n",
    "\n",
    "# communities = G.community_multilevel()\n",
    "\n",
    "num_communities = len(communities)\n",
    "community_sizes = communities.sizes()\n",
    "\n",
    "print(f\"\\n=>Community detection complete!\")\n",
    "print(f\"\\n# COMMUNITY STATISTICS:\")\n",
    "print(f\"   Number of communities: {num_communities}\")\n",
    "print(f\"   Modularity: {communities.modularity:.4f}\")\n",
    "print(f\"   Largest community: {max(community_sizes):,} members\")\n",
    "print(f\"   Smallest community: {min(community_sizes):,} members\")\n",
    "print(f\"   Average community size: {np.mean(community_sizes):.1f}\")\n",
    "\n",
    "# Show size distribution\n",
    "print(f\"\\n# COMMUNITY SIZE DISTRIBUTION:\")\n",
    "size_bins = [1, 10, 50, 100, 500, 1000, 5000, float('inf')]\n",
    "size_labels = ['1-9', '10-49', '50-99', '100-499', '500-999', '1000-4999', '5000+']\n",
    "\n",
    "size_counts = Counter()\n",
    "for size in community_sizes:\n",
    "    for i, threshold in enumerate(size_bins[1:]):\n",
    "        if size < threshold:\n",
    "            size_counts[size_labels[i]] += 1\n",
    "            break\n",
    "\n",
    "for label in size_labels:\n",
    "    count = size_counts[label]\n",
    "    if count > 0:\n",
    "        print(f\"   {label:>10s} members: {count:4d} communities\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067852a",
   "metadata": {},
   "source": [
    "### Visualisations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8af3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree distribution plot saved as 'degree_distribution_2019.png'\n"
     ]
    }
   ],
   "source": [
    "# Plot degree distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Out-degree distribution\n",
    "ax1 = axes[0]\n",
    "degree_counts_out = Counter(degrees_out)\n",
    "degrees_sorted = sorted(degree_counts_out.keys())\n",
    "counts = [degree_counts_out[d] for d in degrees_sorted]\n",
    "\n",
    "ax1.scatter(degrees_sorted, counts, alpha=0.6, s=20, color='#2E86AB')\n",
    "ax1.set_xlabel('Out-Degree (comments made)', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Users', fontsize=11, fontweight='bold')\n",
    "ax1.set_title(f'Out-Degree Distribution - {test_year}', fontsize=12, fontweight='bold')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# In-degree distribution\n",
    "ax2 = axes[1]\n",
    "degree_counts_in = Counter(degrees_in)\n",
    "degrees_sorted_in = sorted(degree_counts_in.keys())\n",
    "counts_in = [degree_counts_in[d] for d in degrees_sorted_in]\n",
    "\n",
    "ax2.scatter(degrees_sorted_in, counts_in, alpha=0.6, s=20, color='#A23B72')\n",
    "ax2.set_xlabel('In-Degree (comments received)', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Users', fontsize=11, fontweight='bold')\n",
    "ax2.set_title(f'In-Degree Distribution - {test_year}', fontsize=12, fontweight='bold')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'degree_distribution_{test_year}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDegree distribution plot saved as 'degree_distribution_{test_year}.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754e3de",
   "metadata": {},
   "source": [
    "### Betweeness centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45b9022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting betweenness centrality calculation...\n",
      "=>  This may take some time for 140k nodes. Watch for progress...\n",
      "\n",
      "X Computation interrupted by user\n",
      "   Time elapsed: 0.1 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Attempting betweenness centrality calculation...\")\n",
    "print(\"=>  This may take some time for 140k nodes. Watch for progress...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Compute betweenness for all nodes\n",
    "    betweenness = G.betweenness(directed=True)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"=> Betweenness computed in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    \n",
    "    # Get top users by betweenness\n",
    "    node_names = G.vs['name']\n",
    "    top_between = sorted(zip(node_names, betweenness), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(\"\\n=> TOP 10 USERS BY BETWEENNESS (Bridges/Connectors):\")\n",
    "    for i, (user, bet) in enumerate(top_between, 1):\n",
    "        print(f\"   {i:2d}. {user:30s} - Betweenness: {bet:.2f}\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nX Computation interrupted by user\")\n",
    "    print(f\"   Time elapsed: {(time.time() - start_time)/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f87456",
   "metadata": {},
   "source": [
    "*=>* This takes a long time so we'll have to go with sampling to get an approximation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a85a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CENTRALITY MEASURES\n",
      "================================================================================\n",
      "Computing fast centrality metrics...\n",
      " Fast metrics computed!\n",
      "\n",
      "Computing approximate betweenness (cutoff=5)...\n",
      " Betweenness computed in 1150.7 seconds\n",
      "\n",
      " Top 10 Most Central Nodes:\n",
      "\n",
      "By Degree (connections):\n",
      "  1. Node 177: 7458 connections\n",
      "  2. Node 69565: 6650 connections\n",
      "  3. Node 46: 5517 connections\n",
      "  4. Node 5210: 4103 connections\n",
      "  5. Node 105604: 1255 connections\n",
      "  6. Node 1093: 1155 connections\n",
      "  7. Node 821: 1149 connections\n",
      "  8. Node 64114: 1081 connections\n",
      "  9. Node 17279: 961 connections\n",
      "  10. Node 487: 960 connections\n",
      "\n",
      "By PageRank (importance):\n",
      "  1. Node 46: 0.005848\n",
      "  2. Node 5210: 0.004594\n",
      "  3. Node 69565: 0.003720\n",
      "  4. Node 177: 0.003482\n",
      "  5. Node 126399: 0.002387\n",
      "  6. Node 132700: 0.002031\n",
      "  7. Node 105604: 0.001869\n",
      "  8. Node 1093: 0.000897\n",
      "  9. Node 64114: 0.000838\n",
      "  10. Node 640: 0.000788\n",
      "\n",
      "By Betweenness (bridge position):\n",
      "  1. Node 177: 1253628857.75\n",
      "  2. Node 69565: 833736426.14\n",
      "  3. Node 46: 403678811.59\n",
      "  4. Node 821: 210775842.49\n",
      "  5. Node 1093: 207918687.57\n",
      "  6. Node 5210: 196801277.63\n",
      "  7. Node 64114: 122737820.54\n",
      "  8. Node 640: 84726788.05\n",
      "  9. Node 43838: 81636769.53\n",
      "  10. Node 487: 79044141.40\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CENTRALITY MEASURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import time\n",
    "\n",
    "# 1. Fast metrics\n",
    "print(\"Computing fast centrality metrics...\")\n",
    "degree_cent = G.degree()\n",
    "pagerank = G.pagerank(directed=True)\n",
    "\n",
    "print(\"=> Fast metrics computed!\")\n",
    "\n",
    "# 2. Approximate betweenness with cutoff\n",
    "print(\"\\nComputing approximate betweenness (cutoff=5)...\")\n",
    "start_time = time.time()\n",
    "betweenness = G.betweenness(directed=True, cutoff=5)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"=> Betweenness computed in {elapsed:.1f} seconds\")\n",
    "\n",
    "# 3. Find top nodes\n",
    "top_n = 10\n",
    "top_degree_idx = sorted(range(num_nodes), key=lambda x: degree_cent[x], reverse=True)[:top_n]\n",
    "top_pagerank_idx = sorted(range(num_nodes), key=lambda x: pagerank[x], reverse=True)[:top_n]\n",
    "top_betweenness_idx = sorted(range(num_nodes), key=lambda x: betweenness[x], reverse=True)[:top_n]\n",
    "\n",
    "print(f\"\\n# Top {top_n} Most Central Nodes:\")\n",
    "print(f\"\\nBy Degree (connections):\")\n",
    "for i, idx in enumerate(top_degree_idx, 1):\n",
    "    print(f\"  {i}. Node {idx}: {degree_cent[idx]} connections\")\n",
    "\n",
    "print(f\"\\nBy PageRank (importance):\")\n",
    "for i, idx in enumerate(top_pagerank_idx, 1):\n",
    "    print(f\"  {i}. Node {idx}: {pagerank[idx]:.6f}\")\n",
    "\n",
    "print(f\"\\nBy Betweenness (bridge position):\")\n",
    "for i, idx in enumerate(top_betweenness_idx, 1):\n",
    "    print(f\"  {i}. Node {idx}: {betweenness[idx]:.2f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b595aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important Bridge Users:\n",
      "  1. u/AnotherTrowaway12\n",
      "      Betweenness: 1,253,628,858\n",
      "      Degree: 7458\n",
      "\n",
      "  2. u/JesusAndSoda\n",
      "      Betweenness: 833,736,426\n",
      "      Degree: 6650\n",
      "\n",
      "  3. u/SQLwitch\n",
      "      Betweenness: 403,678,812\n",
      "      Degree: 5517\n",
      "\n",
      "  4. u/What_I_do_45\n",
      "      Betweenness: 210,775,842\n",
      "      Degree: 1149\n",
      "\n",
      "  5. u/drauch52\n",
      "      Betweenness: 207,918,688\n",
      "      Degree: 1155\n",
      "\n",
      "  6. u/circinia\n",
      "      Betweenness: 196,801,278\n",
      "      Degree: 4103\n",
      "\n",
      "  7. u/ThisNotMyMainAcc\n",
      "      Betweenness: 122,737,821\n",
      "      Degree: 1081\n",
      "\n",
      "  8. u/witchofthewoods89\n",
      "      Betweenness: 84,726,788\n",
      "      Degree: 755\n",
      "\n",
      "  9. u/treatment32\n",
      "      Betweenness: 81,636,770\n",
      "      Degree: 951\n",
      "\n",
      "  10. u/maddiokii\n",
      "      Betweenness: 79,044,141\n",
      "      Degree: 960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/19 03:32:01 WARN TransportChannelHandler: Exception in connection from /192.168.1.236:40841\n",
      "java.io.IOException: Connection timed out\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:47)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:330)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:284)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:259)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:417)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:255)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:356)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:796)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/12/19 17:24:15 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 45543395 ms exceeds timeout 120000 ms\n",
      "25/12/19 17:24:16 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/12/19 17:24:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:24:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:25:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:26:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:27:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:28:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:29:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:30:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/12/19 17:31:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/12/19 17:31:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:31:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/12/19 17:32:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/12/19 17:32:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:32:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/12/19 17:33:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.236:45733\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "# Map node indices to actual usernames\n",
    "top_betweenness_idx = sorted(range(num_nodes), \n",
    "                              key=lambda x: betweenness[x], \n",
    "                              reverse=True)[:10]\n",
    "\n",
    "print(\"\\nTop 10 Most Important Bridge Users:\")\n",
    "for i, idx in enumerate(top_betweenness_idx, 1):\n",
    "    username = G.vs[idx]['name']  # Assuming 'name' attribute has usernames\n",
    "    bet_value = betweenness[idx]\n",
    "    degree = G.degree(idx)\n",
    "    \n",
    "    print(f\"  {i}. u/{username}\")\n",
    "    print(f\"      Betweenness: {bet_value:,.0f}\")\n",
    "    print(f\"      Degree: {degree}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e1813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
